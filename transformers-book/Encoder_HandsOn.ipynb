{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder HandsOn",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNqHhayeTkb4NpfVLyNNqSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boi-doingthings/my-transfomers/blob/main/transformers-book/Encoder_HandsOn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "QIcbRhLY47Cj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H5ObZxj3WYS",
        "outputId": "5f55075d-499e-4423-e3ac-692e6eb847ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[K     |████████████████████████████████| 365 kB 57.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.4.0 huggingface-hub-0.8.1 multiprocess-0.70.13 responses-0.18.0 tokenizers-0.12.1 transformers-4.21.1 urllib3-1.25.11 xxhash-3.0.0\n"
          ]
        }
      ],
      "source": [
        "## Install Transformers and datasets\n",
        "\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy"
      ],
      "metadata": {
        "id": "5DIdhsr53kOI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = [\"The cat is quick and orange\",\n",
        "         \"The orange is tangy and juicy\"]"
      ],
      "metadata": {
        "id": "i4P32IVa4iTa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer to create tokens\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "Foih3n1m3xOr"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = tokenizer(input,return_tensors=\"pt\",padding=True,truncation=True)\n",
        "input_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1Dm_-Nv4hyy",
        "outputId": "709f65a1-4f05-4de5-a9ff-349e921ce645"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1996,  4937,  2003,  4248,  1998,  4589,   102,     0],\n",
              "        [  101,  1996,  4589,  2003,  9745,  2100,  1998, 28900,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Self - Attention"
      ],
      "metadata": {
        "id": "VeHoofHT5XI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import AutoConfig # gives the config file of the model used.\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_ckpt)\n",
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8jUlgJv4guq",
        "outputId": "22e1d4f8-e17f-4a1e-d4d2-d78a00dc6401"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertConfig {\n",
              "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
              "  \"activation\": \"gelu\",\n",
              "  \"architectures\": [\n",
              "    \"DistilBertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.1,\n",
              "  \"dim\": 768,\n",
              "  \"dropout\": 0.1,\n",
              "  \"hidden_dim\": 3072,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"distilbert\",\n",
              "  \"n_heads\": 12,\n",
              "  \"n_layers\": 6,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"qa_dropout\": 0.1,\n",
              "  \"seq_classif_dropout\": 0.2,\n",
              "  \"sinusoidal_pos_embds\": false,\n",
              "  \"tie_weights_\": true,\n",
              "  \"transformers_version\": \"4.21.1\",\n",
              "  \"vocab_size\": 30522\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeds = nn.Embedding(config.vocab_size,config.dim)\n",
        "embeds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "095ZlUI356qM",
        "outputId": "2b0001f1-a5e4-4b82-af67-c3921c0081c8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30522, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeds = embeds(input_tokens['input_ids'])\n",
        "input_embeds.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upnFD62U6Y28",
        "outputId": "59eb020b-01c0-493f-c569-18b1d38e9a6c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  1. Project each token embedding into three vectors called query, key, and value.\n",
        "q=k=v=input_embeds\n",
        "#  2. Compute attention scores. \n",
        "dim_k = numpy.sqrt(k.shape[-1])\n",
        "scores = torch.bmm(q,k.transpose(2,1))/dim_k"
      ],
      "metadata": {
        "id": "usrssURO6nLM"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOh1Um5w6tXM",
        "outputId": "68c42262-10d2-491e-d08e-ec8b5d4115d6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.6978e+01,  2.2458e+00,  5.3122e-01,  8.3515e-01, -7.3148e-01,\n",
              "          -1.8162e-01,  1.6261e-01, -1.4513e+00, -7.2368e-02],\n",
              "         [ 2.2458e+00,  2.8367e+01,  2.9603e-01, -4.6457e-01, -3.5759e-01,\n",
              "           5.5322e-01, -7.1558e-01,  9.4747e-01, -3.3803e-01],\n",
              "         [ 5.3122e-01,  2.9603e-01,  2.6179e+01,  2.2540e-01,  1.3389e+00,\n",
              "           9.8135e-01,  1.3713e+00,  1.8472e+00, -5.1659e-01],\n",
              "         [ 8.3515e-01, -4.6457e-01,  2.2540e-01,  2.9390e+01, -1.6786e+00,\n",
              "           1.4807e+00, -1.6285e+00, -8.5464e-01,  1.7378e+00],\n",
              "         [-7.3148e-01, -3.5759e-01,  1.3389e+00, -1.6786e+00,  2.7546e+01,\n",
              "          -1.5153e+00,  1.1849e+00,  1.4900e+00, -1.3961e+00],\n",
              "         [-1.8162e-01,  5.5322e-01,  9.8135e-01,  1.4807e+00, -1.5153e+00,\n",
              "           2.5874e+01,  1.0427e+00,  8.1405e-01,  6.8843e-02],\n",
              "         [ 1.6261e-01, -7.1558e-01,  1.3713e+00, -1.6285e+00,  1.1849e+00,\n",
              "           1.0427e+00,  2.9313e+01,  2.7255e+00,  6.1797e-01],\n",
              "         [-1.4513e+00,  9.4747e-01,  1.8472e+00, -8.5464e-01,  1.4900e+00,\n",
              "           8.1406e-01,  2.7255e+00,  2.8547e+01,  9.5186e-01],\n",
              "         [-7.2367e-02, -3.3803e-01, -5.1659e-01,  1.7378e+00, -1.3961e+00,\n",
              "           6.8843e-02,  6.1797e-01,  9.5186e-01,  2.9965e+01]],\n",
              "\n",
              "        [[ 2.6978e+01,  2.2458e+00,  1.6261e-01,  8.3515e-01,  7.5250e-01,\n",
              "           1.4019e-01, -1.8162e-01, -8.5542e-01, -1.4513e+00],\n",
              "         [ 2.2458e+00,  2.8367e+01, -7.1558e-01, -4.6457e-01, -3.2524e-01,\n",
              "          -2.6728e-01,  5.5322e-01, -2.8394e-01,  9.4747e-01],\n",
              "         [ 1.6261e-01, -7.1558e-01,  2.9313e+01, -1.6285e+00,  1.6109e+00,\n",
              "          -9.0707e-01,  1.0427e+00, -2.4931e-01,  2.7255e+00],\n",
              "         [ 8.3515e-01, -4.6457e-01, -1.6285e+00,  2.9390e+01, -7.2372e-01,\n",
              "           3.2326e+00,  1.4807e+00,  4.0390e-01, -8.5464e-01],\n",
              "         [ 7.5250e-01, -3.2524e-01,  1.6109e+00, -7.2372e-01,  2.8914e+01,\n",
              "           1.1491e-01,  1.1682e-02,  1.4844e+00, -1.2742e+00],\n",
              "         [ 1.4019e-01, -2.6728e-01, -9.0707e-01,  3.2326e+00,  1.1491e-01,\n",
              "           2.7300e+01, -1.9739e-01, -1.5474e+00, -4.1370e-01],\n",
              "         [-1.8162e-01,  5.5322e-01,  1.0427e+00,  1.4807e+00,  1.1681e-02,\n",
              "          -1.9739e-01,  2.5874e+01,  1.1981e+00,  8.1406e-01],\n",
              "         [-8.5541e-01, -2.8394e-01, -2.4931e-01,  4.0390e-01,  1.4844e+00,\n",
              "          -1.5474e+00,  1.1981e+00,  3.0180e+01, -1.8479e+00],\n",
              "         [-1.4513e+00,  9.4747e-01,  2.7255e+00, -8.5464e-01, -1.2742e+00,\n",
              "          -4.1370e-01,  8.1406e-01, -1.8479e+00,  2.8547e+01]]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDWLIBkD8lAd",
        "outputId": "a8da107e-19dc-4186-eef9-79f910aa67c8"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "# 3. Compute attention weights.\n",
        "weights = F.softmax(scores,dim=-1)\n",
        "# 4. Update the token embeddings.\n",
        "attn_op = torch.bmm(weights,v)\n",
        "attn_op"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taWbrrn970sU",
        "outputId": "e3f98b1a-c1e2-4f17-b6ad-40315702e592"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.8862, -0.7888,  1.1448,  ..., -0.2929,  1.2159,  1.0291],\n",
              "         [ 1.3269, -1.5454,  0.3856,  ..., -0.1901, -0.3826, -1.9612],\n",
              "         [ 0.1785,  2.1488,  1.0524,  ..., -1.1788, -0.6794,  1.5221],\n",
              "         ...,\n",
              "         [ 0.4172,  2.1974,  0.5010,  ...,  0.6061, -1.5345,  1.0498],\n",
              "         [-0.4665, -0.4760, -0.8432,  ..., -1.5794,  0.7461, -0.7338],\n",
              "         [-1.7447,  0.1426,  1.6844,  ..., -0.3214,  1.2646, -0.8988]],\n",
              "\n",
              "        [[ 1.8862, -0.7888,  1.1448,  ..., -0.2929,  1.2159,  1.0291],\n",
              "         [ 1.3269, -1.5454,  0.3856,  ..., -0.1901, -0.3826, -1.9612],\n",
              "         [ 0.4172,  2.1974,  0.5010,  ...,  0.6061, -1.5345,  1.0498],\n",
              "         ...,\n",
              "         [ 1.1877,  1.4300,  0.0981,  ..., -1.2678,  1.5755, -2.7351],\n",
              "         [ 0.2579,  0.4515, -1.1815,  ...,  0.0404,  0.6257, -0.5362],\n",
              "         [-0.4665, -0.4760, -0.8432,  ..., -1.5794,  0.7461, -0.7338]]],\n",
              "       grad_fn=<BmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value):\n",
        " dim_k = query.size(-1)\n",
        " scores = torch.bmm(query, key.transpose(1, 2)) / numpy.sqrt(dim_k)\n",
        " weights = F.softmax(scores, dim=-1)\n",
        " return torch.bmm(weights, value)"
      ],
      "metadata": {
        "id": "Qs-d2-nK80tN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self,embed_dim,head_dim):\n",
        "    super().__init__()\n",
        "    self.query = nn.Linear(embed_dim,head_dim)\n",
        "    self.key = nn.Linear(embed_dim,head_dim)\n",
        "    self.value = nn.Linear(embed_dim,head_dim)\n",
        "\n",
        "  def forward(self,hidden_state):\n",
        "    attn_outputs = scaled_dot_product_attention(\n",
        "    self.query(hidden_state), self.key(hidden_state), self.value(hidden_state))\n",
        "    return attn_outputs\n",
        "\n"
      ],
      "metadata": {
        "id": "ufmQF5Yn9Mdl"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = AttentionHead(config.dim,config.dim//config.n_heads)"
      ],
      "metadata": {
        "id": "Bmg34eat_Scr"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c(input_embeds).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY0sGg9W_g7u",
        "outputId": "50762caa-8230-44fb-8afd-08c400585a1b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.head_dim = config.dim//config.n_heads\n",
        "    self.heads = nn.ModuleList([AttentionHead(config.dim,self.head_dim) for _ in range(config.n_heads)])\n",
        "    self.output_linear = nn.Linear(config.dim,config.dim)\n",
        "  \n",
        "  def forward(self,hidden_state):\n",
        "    self.output = torch.cat([h(hidden_state) for h in self.heads],dim= -1)\n",
        "    self.output = self.output_linear(self.output)\n",
        "    return self.output\n",
        "  "
      ],
      "metadata": {
        "id": "VnbgkX42_tuG"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = MultiHeadAttention(config)"
      ],
      "metadata": {
        "id": "InsxVVgqsUrd"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c(input_embeds).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLicColjsXx0",
        "outputId": "f0487cbc-5fad-48d4-ed8f-ea5898e3f566"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(config.dim, config.hidden_dim)\n",
        "    self.linear_2 = nn.Linear(config.hidden_dim, config.dim)\n",
        "    self.gelu = nn.GELU()\n",
        "    self.dropout = nn.Dropout(config.attention_dropout)\n",
        "  def forward(self, x):\n",
        "    x = self.linear_1(x)\n",
        "    x = self.gelu(x)\n",
        "    x = self.linear_2(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "n6sZaiFisbic"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = FeedForward(config)\n",
        "c(input_embeds).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3KI_Jn4tYkp",
        "outputId": "b798cd15-78e7-4f9b-ad5a-85596c4e9402"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderLayer(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.layer_norm1 = nn.LayerNorm(config.dim)\n",
        "    self.layer_norm2 = nn.LayerNorm(config.dim)\n",
        "    self.Attention = MultiHeadAttention(config)\n",
        "    self.feed_forward = FeedForward(config)\n",
        "\n",
        "  def forward(self,x):\n",
        "    temp = self.layer_norm1(x)\n",
        "    x = x + self.Attention(temp)\n",
        "    hidden_state = self.layer_norm2(x)\n",
        "    return x + self.feed_forward(hidden_state)\n",
        "\n"
      ],
      "metadata": {
        "id": "urxJt18Ftd9j"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_encoder = TransformerEncoderLayer(config)"
      ],
      "metadata": {
        "id": "tvOm5Kf9vqvo"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_encoder(input_embeds).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN-O-Wiiv0RC",
        "outputId": "a667d088-b07f-43bf-fcb0-0d90a745fe67"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Incorporate Position Embeddings"
      ],
      "metadata": {
        "id": "anNYLsq4w2_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.token_embeddings = nn.Embedding(config.vocab_size,\n",
        "                                         config.dim)\n",
        "    self.position_embeddings = nn.Embedding(config.max_position_embeddings,\n",
        "                                            config.dim)\n",
        "    self.layer_norm = nn.LayerNorm(config.dim, eps=1e-12)\n",
        "    self.dropout = nn.Dropout()\n",
        "\n",
        "  def forward(self, input_ids):\n",
        "    # Create position IDs for input sequence\n",
        "    seq_length = input_ids.size(1)\n",
        "    position_ids = torch.arange(seq_length, dtype=torch.long).unsqueeze(0)\n",
        "    # Create token and position embeddings\n",
        "    token_embeddings = self.token_embeddings(input_ids)\n",
        "    position_embeddings = self.position_embeddings(position_ids)\n",
        "    # Combine token and position embeddings\n",
        "    embeddings = token_embeddings + position_embeddings\n",
        "    embeddings = self.layer_norm(embeddings)\n",
        "    embeddings = self.dropout(embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "5rTRgZEswBca"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e =Embeddings(config)"
      ],
      "metadata": {
        "id": "KgZTT9Bi72Nb"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e(input_tokens.input_ids).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DILkY9ln76RL",
        "outputId": "84fa073c-55f4-432a-c33a-8739914f82e9"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 9, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.embeddings = Embeddings(config)\n",
        "    self.layers = nn.ModuleList([TransformerEncoderLayer(config) for _ in range(config.n_layers)])\n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x)\n",
        "    for layer in self.layers:\n",
        "       x = layer(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "OlX6b5eAxzHx"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trx = TransformerEncoder(config)"
      ],
      "metadata": {
        "id": "9KsYaSW35vUd"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trx(input_tokens.input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHruvJqj5zt0",
        "outputId": "9dc06fe8-40e6-48e9-d051-46dc95f3a479"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.6523, -1.1900, -4.7558,  ..., -0.2136, -0.4529,  0.2156],\n",
              "         [ 2.5483, -0.2638,  0.1308,  ...,  1.9346, -4.1408,  2.4937],\n",
              "         [-0.1966, -4.2770, -0.1808,  ...,  0.2456,  0.8316, -1.1160],\n",
              "         ...,\n",
              "         [-4.2977, -1.7213,  0.6988,  ..., -0.2712, -0.8062,  0.1393],\n",
              "         [-1.3997, -0.0491,  0.6676,  ...,  0.7598,  0.2390,  0.2701],\n",
              "         [-0.8013, -1.2029, -0.4760,  ...,  0.8523, -2.0018, -1.4756]],\n",
              "\n",
              "        [[-3.8127, -1.3154, -5.0701,  ..., -0.6410, -0.6948, -0.6807],\n",
              "         [-0.5961, -0.0663, -0.0165,  ...,  1.8785, -0.6121,  0.1930],\n",
              "         [-3.2779, -0.7309, -0.8722,  ...,  0.2890, -0.2289, -0.4353],\n",
              "         ...,\n",
              "         [-0.5368, -0.8194,  0.5627,  ..., -0.3873, -0.6835, -0.0738],\n",
              "         [-0.1412, -0.4684, -0.5600,  ..., -0.5834,  0.7925,  0.1550],\n",
              "         [-0.1805,  0.5588,  0.1084,  ...,  1.7335, -2.1849, -0.4564]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1yZaRVSW56vs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}